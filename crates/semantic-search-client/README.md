# Semantic Search Client

Rust library for managing semantic memory contexts with multiple index types (BM25 and vector embeddings), enabling both fast keyword search and intelligent semantic search capabilities across text and code.

[![Crate](https://img.shields.io/crates/v/semantic_search_client.svg)](https://crates.io/crates/semantic_search_client)
[![Documentation](https://docs.rs/semantic_search_client/badge.svg)](https://docs.rs/semantic_search_client)

## Features

- **Async-First Design**: Built for modern async Rust applications with tokio
- **Semantic Memory Management**: Create, store, and search through semantic memory contexts
- **Pattern Filtering**: Include/exclude files using glob-style patterns during indexing
- **Multiple Index Types**: Choose between Fast (BM25) for keyword search or Best (semantic) for intelligent search
- **Vector Embeddings**: Generate high-quality text embeddings for semantic similarity search
- **Multi-Platform Support**: Works on macOS, Windows, and Linux with optimized backends
- **Hardware Acceleration**: Uses Metal on macOS and optimized backends on other platforms
- **File Processing**: Process various file types including text, markdown, JSON, and code
- **Persistent Storage**: Save contexts to disk for long-term storage and retrieval
- **Background Processing**: Non-blocking indexing with progress tracking and cancellation
- **Parallel Processing**: Efficiently process large directories with parallel execution
- **Memory Efficient**: Stream large files and directories without excessive memory usage
- **Cross-Platform Compatibility**: Fallback mechanisms for all platforms and architectures
- **ðŸ†• Configurable File Limits**: Built-in protection against indexing too many files (default: 5,000 files)
- **ðŸ†• Database Settings Integration**: Configurable chunk sizes, overlap, and limits

## Installation

Add this to your `Cargo.toml`:

```toml
[dependencies]
semantic_search_client = "0.1.0"
```

## Quick Start

```rust
use semantic_search_client::{AsyncSemanticSearchClient, AddContextRequest, Result};
use std::path::PathBuf;

#[tokio::main]
async fn main() -> Result<()> {
    // Create a new async client with default settings
    let client = AsyncSemanticSearchClient::new_with_default_dir().await?;
    
    // Add a context using the new structured request API
    let request = AddContextRequest {
        path: PathBuf::from("/path/to/project"),
        name: "My Project".to_string(),
        description: "Code and documentation for my project".to_string(),
        persistent: true,
        include_patterns: Some(vec!["**/*.rs".to_string(), "**/*.md".to_string()]),
        exclude_patterns: Some(vec!["target/**".to_string(), "**/.git/**".to_string()]),
    };
    
    let (operation_id, _cancel_token) = client.add_context(request).await?;
    println!("Started indexing with operation ID: {}", operation_id);
    
    // Search across all contexts
    let results = client.search_all("implement authentication", None).await?;
    
    // Print the results
    for (context_id, context_results) in results {
        println!("Results from context {}", context_id);
        for result in context_results {
            println!("Score: {}", result.distance);
            if let Some(text) = result.text() {
                println!("Text: {}", text);
            }
        }
    }
    
    Ok(())
}
```

## Testing

The library includes comprehensive tests for all components. By default, tests use a mock embedder to avoid downloading models.

### Running Tests with Mock Embedders (Default)

```bash
cargo test
```

### Running Tests with Real Embedders

To run tests with real embedders (which will download models), set the `MEMORY_BANK_USE_REAL_EMBEDDERS` environment variable:

```bash
MEMORY_BANK_USE_REAL_EMBEDDERS=1 cargo test
```

## Core Concepts

### Memory Contexts

A memory context is a collection of related text or code that has been processed and indexed for semantic search. Contexts can be created from:

- Files
- Directories
- Raw text

Contexts can be either:

- **Volatile**: Temporary and lost when the program exits
- **Persistent**: Saved to disk and can be reloaded later

### Data Points

Each context contains data points, which are individual pieces of text with associated metadata and vector embeddings. Data points are the atomic units of search.

### Index Types

The library supports two index types for different use cases:

**Fast (BM25)**:
- Lightning-fast keyword-based search
- Instant indexing with minimal resource usage
- Perfect for logs, configuration files, and large codebases
- Available on all platforms

**Best (Semantic)**:
- Intelligent semantic search with natural language understanding
- Uses vector embeddings with different backends based on platform:
  - **macOS/Windows**: Candle with optimized models
  - **Linux (non-ARM)**: Candle for embeddings
  - **Linux (ARM64)**: Falls back to BM25 when semantic models unavailable

## Index Types and Backends

The library supports multiple index types with automatic backend selection:

1. **Candle**: Good performance, used on Linux (non-ARM)
2. **BM25**: Keyword matching, used on Linux ARM64

The default selection logic prioritizes performance where possible:
- macOS/Windows: ONNX is the default
- Linux (non-ARM): Candle is the default
- Linux ARM64: BM25 is the default
- ARM64: BM25 is the default

## Detailed Usage

### Creating a Client

```rust
// Create async client with default settings
let client = AsyncSemanticSearchClient::new_with_default_dir().await?;

// With custom directory
let client = AsyncSemanticSearchClient::new("/path/to/storage").await?;

// With custom configuration
let config = SemanticSearchConfig::default()
    .set_max_files(10000)      // Allow up to 10,000 files
    .set_chunk_size(1024);     // Custom chunk size
let client = AsyncSemanticSearchClient::with_config("/path/to/storage", config).await?;
```
```

### Configuration Options

The `SemanticSearchConfig` struct provides various configuration options:

```rust
let config = SemanticSearchConfig {
    chunk_size: 512,           // Size of text chunks for processing
    chunk_overlap: 128,        // Overlap between chunks
    default_results: 5,        // Default number of search results
    model_name: "all-MiniLM-L6-v2".to_string(),
    timeout: 30000,            // 30 seconds
    base_dir: PathBuf::from("/path/to/storage"),
    max_files: 5000,          // Maximum files allowed in a directory
};

// Or use builder methods
let config = SemanticSearchConfig::default()
    .set_max_files(10000)     // Custom file limit
    .set_chunk_size(1024)     // Custom chunk size
    .set_chunk_overlap(256);  // Custom overlap

// Just set file limit
let config = SemanticSearchConfig::with_max_files(15000);
```

### File Limit Protection

The client includes built-in protection against indexing too many files:

```rust
// This will fail if the directory contains more than 5,000 files
let result = client.add_context_from_directory(
    "/huge/workspace",
    "Workspace",
    "Too many files",
    true,
    None,
);

// Check for specific error
match result {
    Err(SemanticSearchError::InvalidArgument(msg)) => {
        println!("Directory exceeds file limit: {}", msg);
        // Example message:
        // "Directory contains 12,847 files, which exceeds the maximum 
        //  limit of 5,000 files. Please choose a smaller directory or 
        //  increase the max_files limit in the configuration."
    }
    _ => { /* handle other cases */ }
}

// To handle larger directories, increase the limit:
let config = SemanticSearchConfig::with_max_files(20000);
let client = SemanticSearchClient::with_config(path, config)?;
```

### Adding Contexts

```rust
use semantic_search_client::AddContextRequest;
use std::path::PathBuf;

// Add context with pattern filtering
let request = AddContextRequest {
    path: PathBuf::from("/path/to/codebase"),
    name: "Rust Codebase".to_string(),
    description: "Main Rust project source code".to_string(),
    persistent: true,
    include_patterns: Some(vec![
        "**/*.rs".to_string(),
        "**/*.toml".to_string(),
        "**/*.md".to_string(),
    ]),
    exclude_patterns: Some(vec![
        "target/**".to_string(),
        "**/.git/**".to_string(),
        "**/node_modules/**".to_string(),
    ]),
};

let (operation_id, cancel_token) = client.add_context(request).await?;
println!("Started indexing with operation ID: {}", operation_id);

// Add context without pattern filtering
let simple_request = AddContextRequest {
    path: PathBuf::from("/path/to/docs"),
    name: "Documentation".to_string(),
    description: "Project documentation".to_string(),
    persistent: true,
    include_patterns: None,
    exclude_patterns: None,
};

let (operation_id, _) = client.add_context(simple_request).await?;

// Monitor progress (the client runs indexing in background)
let status = client.get_status_data().await?;
println!("Active operations: {}", status.active_count);
```
```

### Searching

```rust
// Search across all contexts
let all_results = client.search_all("authentication implementation", None).await?;
for (context_id, results) in all_results {
    println!("Results from context {}", context_id);
    for result in results {
        println!("  Score: {}", result.distance);
        if let Some(text) = result.text() {
            println!("  Text: {}", text);
        }
    }
}

// Get all contexts first, then search specific ones
let contexts = client.get_contexts().await;
for context in &contexts {
    println!("Available context: {} ({})", context.name, context.id);
}
```
```

### Managing Contexts

```rust
// Get all contexts
let contexts = client.get_contexts().await;
for context in contexts {
    println!("Context: {} ({})", context.name, context.id);
    println!("  Description: {}", context.description);
    println!("  Created: {}", context.created_at);
    println!("  Items: {}", context.item_count);
    println!("  Include patterns: {:?}", context.include_patterns);
    println!("  Exclude patterns: {:?}", context.exclude_patterns);
}

// Remove contexts
client.remove_context_by_id("context-id").await?;
client.remove_context_by_name("Context Name").await?;
client.remove_context_by_path("/path/to/indexed/directory").await?;

// Cancel ongoing operations
client.cancel_operation(operation_id).await?;
client.cancel_all_operations().await?;

// Get system status
let status = client.get_status_data().await?;
println!("Total contexts: {}", status.total_contexts);
println!("Active operations: {}", status.active_count);
```
```

## Pattern Filtering

The library supports glob-style pattern filtering to control which files are indexed:

### Include Patterns
Only files matching these patterns will be indexed:
```rust
let request = AddContextRequest {
    // ... other fields
    include_patterns: Some(vec![
        "**/*.rs".to_string(),      // All Rust files
        "**/*.md".to_string(),      // All Markdown files
        "src/**/*.toml".to_string(), // TOML files in src directory
    ]),
    exclude_patterns: None,
};
```

### Exclude Patterns
Files matching these patterns will be skipped:
```rust
let request = AddContextRequest {
    // ... other fields
    include_patterns: None,
    exclude_patterns: Some(vec![
        "target/**".to_string(),        // Build artifacts
        "**/.git/**".to_string(),       // Git metadata
        "**/node_modules/**".to_string(), // Node.js dependencies
        "**/*.log".to_string(),         // Log files
    ]),
};
```

### Combined Filtering
Use both include and exclude patterns for precise control:
```rust
let request = AddContextRequest {
    // ... other fields
    include_patterns: Some(vec![
        "**/*.rs".to_string(),
        "**/*.toml".to_string(),
        "**/*.md".to_string(),
    ]),
    exclude_patterns: Some(vec![
        "target/**".to_string(),
        "**/tests/**".to_string(),  // Skip test files
        "**/*_test.rs".to_string(), // Skip test files
    ]),
};
```

### Pattern Syntax
- `**` matches any number of directories
- `*` matches any characters within a single path segment
- `?` matches a single character
- `[abc]` matches any character in the set
- `{a,b,c}` matches any of the alternatives

## Advanced Features

### Custom Index Types

The library supports different embedding backends:

```rust
// Use ONNX (fastest, used on macOS and Windows)
#[cfg(any(target_os = "macos", target_os = "windows"))]
let client = SemanticSearchClient::with_embedding_type(
    "/path/to/storage",
    EmbeddingType::Onnx,
)?;

// Use Candle (used on Linux non-ARM)
#[cfg(all(target_os = "linux", not(target_arch = "aarch64")))]
let client = SemanticSearchClient::with_embedding_type(
    "/path/to/storage",
    EmbeddingType::Candle,
)?;

// Use BM25 (used on Linux ARM64)
#[cfg(all(target_os = "linux", target_arch = "aarch64"))]
let client = SemanticSearchClient::with_embedding_type(
    "/path/to/storage",
    EmbeddingType::BM25,
)?;
```
```

### Parallel Processing

For large directories, the library automatically uses parallel processing to speed up indexing:

```rust
use rayon::prelude::*;

// Configure the global thread pool (optional)
rayon::ThreadPoolBuilder::new()
    .num_threads(8)
    .build_global()
    .unwrap();

// The client will use the configured thread pool
let client = SemanticSearchClient::new_with_default_dir()?;
```

## File Limit Management

The semantic search client includes built-in protection against indexing too many files, which can overwhelm system resources and cause performance issues.

### Default Behavior

- **Default limit**: 5,000 files per directory
- **Early detection**: Files are counted before indexing begins
- **Clear error messages**: Users are informed of the limit and how to resolve it
- **Configurable**: Limits can be adjusted based on your needs

### Configuring File Limits

```rust
// Default limit (5,000 files)
let client = SemanticSearchClient::new_with_default_dir()?;

// Custom limit for larger projects
let config = SemanticSearchConfig::with_max_files(15000);
let client = SemanticSearchClient::with_config(path, config)?;

// No limit (use with caution!)
let config = SemanticSearchConfig::with_max_files(usize::MAX);
let client = SemanticSearchClient::with_config(path, config)?;

// Chainable configuration
let config = SemanticSearchConfig::default()
    .set_max_files(10000)
    .set_chunk_size(1024);
```

### Handling File Limit Errors

```rust
match client.add_context_from_directory(path, "name", "desc", true, None) {
    Ok(context_id) => {
        println!("Successfully indexed directory: {}", context_id);
    }
    Err(SemanticSearchError::InvalidArgument(msg)) if msg.contains("exceeds the maximum limit") => {
        println!("Directory has too many files: {}", msg);
        
        // Options to resolve:
        // 1. Choose a smaller subdirectory
        // 2. Increase the file limit
        // 3. Index subdirectories separately
    }
    Err(e) => {
        println!("Other error: {}", e);
    }
}
```

### Best Practices

1. **Start with subdirectories**: Instead of indexing entire workspaces, focus on specific components
2. **Use appropriate limits**: 
   - Small projects: 1,000-5,000 files
   - Medium projects: 5,000-15,000 files  
   - Large projects: 15,000+ files (consider splitting)
3. **Monitor performance**: Larger indexes take more memory and longer to search
4. **Exclude unnecessary files**: The client automatically skips common build artifacts and hidden files

### Example: Handling Large Codebases

```rust
// Instead of indexing the entire workspace
// let context = client.add_context_from_directory("/workspace", ...); // Might fail!

// Index important subdirectories separately
let src_context = client.add_context_from_directory("/workspace/src", "Source Code", "Main source code", true, None)?;
let docs_context = client.add_context_from_directory("/workspace/docs", "Documentation", "Project docs", true, None)?;
let tests_context = client.add_context_from_directory("/workspace/tests", "Tests", "Test files", true, None)?;

// Or increase the limit for the entire workspace
let config = SemanticSearchConfig::with_max_files(25000);
let client = SemanticSearchClient::with_config(path, config)?;
let workspace_context = client.add_context_from_directory("/workspace", "Full Workspace", "Complete codebase", true, None)?;
```

## Performance Considerations

- **File Count Limits**: The default 5,000 file limit prevents system overload. Adjust based on your hardware:
  - 8GB RAM: 5,000-10,000 files
  - 16GB RAM: 10,000-20,000 files
  - 32GB+ RAM: 20,000+ files
- **Memory Usage**: Each file adds to memory usage. Monitor system resources when indexing large directories
- **Disk Space**: Persistent contexts store both the original text and vector embeddings
- **Embedding Speed**: The first embedding operation may be slower as models are loaded
- **Hardware Acceleration**: On macOS, Metal is used for faster embedding generation
- **Platform Differences**: Performance may vary based on the selected embedding backend
- **Indexing Time**: Larger file counts increase indexing time exponentially

## Platform-Specific Features

- **macOS**: Uses Metal for hardware-accelerated embeddings via ONNX Runtime and Candle
- **Windows**: Uses optimized CPU execution via ONNX Runtime and Candle
- **Linux (non-ARM)**: Uses Candle for embeddings
- **Linux ARM64**: Uses BM25 keyword-based embeddings as a fallback

## Error Handling

The library uses a custom error type `SemanticSearchError` that implements the standard `Error` trait:

```rust
use semantic_search_client::{SemanticSearchClient, SemanticSearchError, Result};

fn process() -> Result<()> {
    let client = SemanticSearchClient::new_with_default_dir()?;
    
    // Handle specific error types
    match client.search_context("invalid-id", "query", 5) {
        Ok(results) => println!("Found {} results", results.len()),
        Err(SemanticSearchError::ContextNotFound(id)) => 
            println!("Context not found: {}", id),
        Err(e) => println!("Error: {}", e),
    }
    
    // Handle file limit errors
    match client.add_context_from_directory("/large/directory", "name", "desc", true, None) {
        Ok(context_id) => println!("Successfully indexed: {}", context_id),
        Err(SemanticSearchError::InvalidArgument(msg)) if msg.contains("exceeds the maximum limit") => {
            println!("File limit exceeded: {}", msg);
            // Suggest solutions:
            // 1. Use a smaller directory
            // 2. Increase max_files in configuration
            // 3. Index subdirectories separately
        }
        Err(SemanticSearchError::InvalidPath(path)) => 
            println!("Invalid path: {}", path),
        Err(e) => println!("Other error: {}", e),
    }
    
    Ok(())
}
```

### Common Error Types

- `InvalidArgument`: Configuration issues, including file limit violations
- `InvalidPath`: Path doesn't exist or isn't accessible
- `ContextNotFound`: Trying to access a non-existent context
- `OperationFailed`: General operation failures
- `IoError`: File system or network errors
- `EmbeddingError`: Issues with embedding generation
```

## Migration Guide

### Upgrading from Previous Versions

If you're upgrading from a version without file limits, your existing code will continue to work with the default 5,000 file limit. However, you may encounter new errors if you were previously indexing large directories.

#### Before (Previous Versions)
```rust
// This would index any size directory
let client = SemanticSearchClient::new_with_default_dir()?;
let context = client.add_context_from_directory("/huge/workspace", "name", "desc", true, None)?;
```

#### After (Current Version)
```rust
// This may now fail if directory has > 5,000 files
let client = SemanticSearchClient::new_with_default_dir()?;
match client.add_context_from_directory("/huge/workspace", "name", "desc", true, None) {
    Ok(context) => println!("Success: {}", context),
    Err(SemanticSearchError::InvalidArgument(msg)) if msg.contains("exceeds the maximum limit") => {
        // Handle file limit error - increase limit or use smaller directory
        let config = SemanticSearchConfig::with_max_files(20000);
        let client = SemanticSearchClient::with_config(path, config)?;
        let context = client.add_context_from_directory("/huge/workspace", "name", "desc", true, None)?;
    }
    Err(e) => return Err(e),
}
```

#### Recommended Migration Strategy
1. **Test your existing code** with the new version
2. **Identify directories** that exceed the 5,000 file limit
3. **Choose an approach**:
   - Increase the limit: `SemanticSearchConfig::with_max_files(N)`
   - Split large directories into smaller contexts
   - Focus on specific subdirectories instead of entire workspaces

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the terms specified in the repository's license file.
